# Hi, I'm Gavin Sidhu 👋

## Data Engineer & Cloud Enthusiast

I'm a data engineer with a passion for building efficient, scalable data pipelines and infrastructure. Currently working at Collins Aerospace where I design and implement ETL solutions, optimize data workflows, and ensure data quality across enterprise systems.

### 🛠️ Technical Toolkit

- **Languages**: SQL, Python, Java
- **Data Engineering**: ETL/ELT, Data Pipelines, Data Migration, Data Validation
- **Cloud & Tools**: AWS (Certified Cloud Practitioner), Snowflake, Matillion ETL, Dagster, dbt
- **Data Analysis**: Jupyter Notebook, Tableau, Pandas, NumPy
- **DevOps**: Docker, Version Control (Git)

### 🔍 What I'm Currently Focused On

- Building scalable cloud-based data infrastructure
- Automating data pipelines for improved reliability and efficiency
- Implementing data quality frameworks and monitoring
- Exploring modern data stack technologies

### 📚 Education

- MS in Computer Science (Data Science Concentration) - UNC Charlotte
- BS in Computer Science (Data Science Concentration) - UNC Charlotte
- Minor in Management Information Systems

### 🌱 Current Learning Path

I'm currently expanding my knowledge in:
- Dagster/Airflow for workflow orchestration
- dbt for data transformation
- Advanced Snowflake features
- Building event-driven data pipelines

### 📊 Featured Projects

- **Stock ETL Pipeline**: End-to-end data pipeline built with Dagster, PostgreSQL, and dbt that extracts stock data from YFinance, applies transformations, and generates trading signals. Features incremental loading, containerized deployment with Docker, automated backtesting of different window sizes, and a Discord notification system for trading alerts.

- **Twitter Topic Analysis**: Implementation of the Apriori algorithm to discover patterns and associations in Twitter datasets, extracting meaningful insights from social media content.

### 📫 Connect With Me

- LinkedIn: [linkedin.com/in/gavinsidhu2001](https://linkedin.com/in/gavinsidhu2001)
- Email: gsidhu6666@gmail.com

---

*I'm always open to collaborating on interesting data engineering projects or discussing data architecture challenges. Feel free to reach out!*
